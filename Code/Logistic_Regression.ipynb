{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Cleaning'''\n",
    "df = pd.read_csv(r\"D:\\Northeastern Semester 1\\Projects\\ml_project\\Data_Set\\Vehicle_Coupon.csv\")\n",
    "df.drop(['car', 'direction_same', 'toCoupon_GEQ5min'], axis=1, inplace=True)\n",
    "df['temperature'] = df['temperature'].astype(str)\n",
    "df = df.apply(lambda x: x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create dummies and split data'''\n",
    "df_ohe = pd.get_dummies(df)\n",
    "X, y = df_ohe.drop(['Y'], axis=1), df_ohe['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self,X,y, batchSize = 64,learningRate = 0.001, tolerance = 0.00005, maxIteration = 2000):\n",
    "        self.X = X\n",
    "        self.y =y\n",
    "        self.tolerance = tolerance\n",
    "        self.maxIteration = maxIteration\n",
    "        self.learningRate = learningRate\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def splitData(self):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "        return X_train, y_train, X_valid, y_valid, X_test, y_test \n",
    "\n",
    "    def add_x0(self, X):\n",
    "        return np.column_stack([np.ones([X.shape[0], 1]), X])\n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "        sig = 1/(1+np.exp(-z))\n",
    "        return sig\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        pred_ =np.log(np.ones(X.shape[0])+np.exp(X.dot(self.w))) - X.dot(self.w).dot(y)\n",
    "        cost = pred_.sum( )\n",
    "        return cost\n",
    "    \n",
    "    def gradient(self,X,y):\n",
    "        sigmoid = self.sigmoid(X.dot(self.w))\n",
    "        grad = (sigmoid -y ).dot(X)\n",
    "        return grad\n",
    "    \n",
    "    def gradientDescent(self, X, y):\n",
    "        errors = []\n",
    "        last = float('inf')\n",
    "        \n",
    "        for i in range(self.maxIteration):\n",
    "            self.w = self.w - self.learningRate*self.gradient(X,y)\n",
    "            curr = self.costFunction(X,y)\n",
    "            \n",
    "            diff = last - curr\n",
    "            last - curr\n",
    "            \n",
    "            errors.append(curr)\n",
    "            \n",
    "            if diff < self.tolerance:\n",
    "                print(\"The model stopped Learning\")\n",
    "                break\n",
    "        # self.plot_cost(errors)\n",
    "\n",
    "\n",
    "    def stochasticGD(self, X, y):\n",
    "        X, y = np.array(X, dtype=np.float64), np.array(y, dtype=np.float64)\n",
    "        XY = np.c_[X.reshape(X.shape[0], X.shape[1]), y.reshape(X.shape[0], 1)]\n",
    "        \n",
    "        \n",
    "        # Set seed\n",
    "        np.random.seed(2022)\n",
    "        errors = []\n",
    "\n",
    "        for i in tqdm(range(self.maxIteration)):\n",
    "        # Shuffle x and y\n",
    "          np.random.shuffle(XY)\n",
    "\n",
    "          start = 0\n",
    "          stop = start + self.batchSize\n",
    "          X_batch, y_batch = XY[start:stop, :-1], XY[start:stop, -1]\n",
    "\n",
    "          \n",
    "          last_error = float('inf')\n",
    "\n",
    "          # Recalculating the difference\n",
    "          self.w = self.w - self.learningRate * self.gradient(X_batch, y_batch)\n",
    "          current_error = self.costFunction(X, y)\n",
    "         \n",
    "          diff = last_error - current_error\n",
    "          last_error = current_error\n",
    "\n",
    "          errors.append(current_error)\n",
    "          if np.abs(diff) < self.tolerance:\n",
    "              print('Model stopped learning')\n",
    "              break\n",
    "        print(self.w)\n",
    "        #self.plot_rmse(errors)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        pred = self.sigmoid(X.dot(self.w))\n",
    "        return np.around(pred)\n",
    "        \n",
    "    def evaluate(self, y, y_hat):\n",
    "        \n",
    "        y = (y == 1)\n",
    "        y_hat = (y_hat == 1)\n",
    "        \n",
    "        accuracy = (y == y_hat).sum() / y.size\n",
    "        precision = (y & y_hat).sum() / y_hat.sum()\n",
    "        recall = (y & y_hat).sum() / y.sum()\n",
    "\n",
    "        print(\"Accuracy is\", accuracy)\n",
    "        print('Recall is', recall)\n",
    "        print('precision is ', precision)\n",
    "        \n",
    "        return recall, precision, accuracy\n",
    "    \n",
    "    def fit(self):\n",
    "\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = self.splitData()\n",
    "        self.w = np.ones(X_train.shape[1], dtype = np.float64)*0\n",
    "        self.stochasticGD(X_train, y_train)\n",
    "        \n",
    "        #print(self.w)\n",
    "        \n",
    "        y_hat_train = self.predict(X_train)\n",
    "        recall, precision, accuracy = self.evaluate(y_train,y_hat_train)\n",
    "\n",
    "\n",
    "    def validation(self):\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = self.splitData()\n",
    "        y_hat_valid = self.predict(X_valid)\n",
    "        recall, precision, accuracy  = self.evaluate(y_valid, y_hat_valid)\n",
    "\n",
    "    def test(self):\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = self.splitData()\n",
    "        y_hat_test = self.predict(X_test)\n",
    "        recall, precision, accuracy  = self.evaluate(y_test, y_hat_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:42<00:00, 47.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.11303687e-02 -9.59628800e-02  5.34497184e-02 -4.08328138e-01\n",
      " -2.29481804e-01  3.77762890e-01 -6.80413413e-02 -2.73047103e-02\n",
      "  2.52714925e-01 -3.54592994e-01  2.09422523e-01 -1.05693916e-01\n",
      " -2.12896358e-01  3.98830018e-01 -3.58392717e-02  9.89713515e-02\n",
      "  1.71076643e-02  6.99607861e-02 -1.33033623e-01  2.66760638e-02\n",
      "  1.84677859e-01 -6.80413413e-02 -7.92193557e-01  8.46653964e-01\n",
      " -2.76047996e-01 -4.01080792e-01  7.02908125e-01  4.50565183e-01\n",
      " -3.70325439e-01 -1.89096305e-02  9.91493746e-02  2.02968276e-02\n",
      "  3.44017489e-02 -7.85514279e-02 -3.08281370e-02  1.34178545e-01\n",
      "  4.29027891e-02 -9.90222582e-02  5.68616570e-02 -3.33897195e-02\n",
      " -1.11485225e-02  1.55402288e-01 -1.21305901e-01  9.06815996e-02\n",
      "  6.40183157e-02 -4.37704889e-02 -3.30752551e-01  1.84622376e-01\n",
      "  1.30622000e-01  7.55000923e-02  1.61037246e-01 -1.68002739e-01\n",
      " -4.45404388e-03  2.23941205e-02  2.07309946e-02 -3.39699627e-03\n",
      "  1.71756306e-01 -1.42882154e-01  7.31875075e-03  6.20712756e-02\n",
      "  2.75214449e-01  1.45224044e-01 -6.75413150e-02 -2.69359087e-01\n",
      "  4.24935189e-02  1.27406785e-02  5.11056773e-02 -3.30809149e-02\n",
      " -3.09322709e-02  7.80012415e-02 -9.09257669e-02 -2.98043176e-02\n",
      "  2.63676537e-03  1.01337754e-02 -1.42239493e-01  5.62705781e-02\n",
      " -2.95607909e-03  1.72704779e-01  1.06926114e-01  2.19916967e-01\n",
      " -1.11348309e-01 -1.68730751e-01 -1.93293223e-01  7.49667545e-04\n",
      "  1.88775255e-01  7.14444450e-02 -1.25017339e-01 -5.24052454e-02\n",
      " -2.55737166e-03  3.26992360e-01  2.43747153e-01  1.06617415e-01\n",
      " -8.10213921e-02 -5.16095791e-01  6.82031232e-02  6.52676185e-02\n",
      " -3.43939721e-02 -4.63335308e-02  2.74965053e-02 -6.93037431e-02\n",
      " -8.31880673e-02  1.37365397e-01  2.44866255e-03  9.29174955e-02\n",
      "  1.04159211e-01  1.64420227e-01  5.78586112e-02 -1.07526796e-01\n",
      " -1.38671509e-01]\n",
      "Accuracy is 0.6892424669107293\n",
      "Recall is 0.7668726823238566\n",
      "precision is  0.7104901511681173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7027027027027027\n",
      "Recall is 0.7837301587301587\n",
      "precision is  0.7181818181818181\n"
     ]
    }
   ],
   "source": [
    "lr.validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6786652653704677\n",
      "Recall is 0.818266110338433\n",
      "precision is  0.6798921417565486\n"
     ]
    }
   ],
   "source": [
    "lr.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_944\\1736908994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbias_variance_decomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Hemant\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "x_train = X_train.values\n",
    "x_test = X_test.values\n",
    "Y_train = y_train.values\n",
    "Y_test = y_test.values\n",
    "\n",
    "mse, bias, var = bias_variance_decomp(lr, x_train, Y_train, x_test, Y_test, loss='mse', num_rounds=200, random_seed=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b8e6af7e1c800dc5745a28ff6ca8872762767d15c22a299591d50db6a7acdf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
