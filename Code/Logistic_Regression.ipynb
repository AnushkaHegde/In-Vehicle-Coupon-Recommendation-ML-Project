{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Cleaning'''\n",
    "df = pd.read_csv(r\"D:\\Northeastern Semester 1\\Projects\\ml_project\\Data_Set\\Vehicle_Coupon.csv\")\n",
    "df.drop(['car', 'direction_same', 'toCoupon_GEQ5min'], axis=1, inplace=True)\n",
    "df['temperature'] = df['temperature'].astype(str)\n",
    "df = df.apply(lambda x: x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create dummies and split data'''\n",
    "df_ohe = pd.get_dummies(df)\n",
    "X, y = df_ohe.drop(['Y'], axis=1), df_ohe['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self,X,y, batchSize = 32,learningRate = 0.001, tolerance = 0.00005, maxIteration = 2000):\n",
    "        self.X = X\n",
    "        self.y =y\n",
    "        self.tolerance = tolerance\n",
    "        self.maxIteration = maxIteration\n",
    "        self.learningRate = learningRate\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def splitData(self):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "        return X_train, y_train, X_valid, y_valid, X_test, y_test \n",
    "\n",
    "    def add_x0(self, X):\n",
    "        return np.column_stack([np.ones([X.shape[0], 1]), X])\n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "        sig = 1/(1+np.exp(-z))\n",
    "        return sig\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        pred_ =np.log(np.ones(X.shape[0])+np.exp(X.dot(self.w))) - X.dot(self.w).dot(y)\n",
    "        cost = pred_.sum( )\n",
    "        return cost\n",
    "    \n",
    "    def gradient(self,X,y):\n",
    "        sigmoid = self.sigmoid(X.dot(self.w))\n",
    "        grad = (sigmoid -y ).dot(X)\n",
    "        return grad\n",
    "    \n",
    "    def gradientDescent(self, X, y):\n",
    "        errors = []\n",
    "        last = float('inf')\n",
    "        \n",
    "        for i in range(self.maxIteration):\n",
    "            self.w = self.w - self.learningRate*self.gradient(X,y)\n",
    "            curr = self.costFunction(X,y)\n",
    "            \n",
    "            diff = last - curr\n",
    "            last - curr\n",
    "            \n",
    "            errors.append(curr)\n",
    "            \n",
    "            if diff < self.tolerance:\n",
    "                print(\"The model stopped Learning\")\n",
    "                break\n",
    "        # self.plot_cost(errors)\n",
    "\n",
    "\n",
    "    def stochasticGD(self, X, y):\n",
    "        X, y = np.array(X, dtype=np.float64), np.array(y, dtype=np.float64)\n",
    "        XY = np.c_[X.reshape(X.shape[0], X.shape[1]), y.reshape(X.shape[0], 1)]\n",
    "        \n",
    "        \n",
    "        # Set seed\n",
    "        np.random.seed(2022)\n",
    "        errors = []\n",
    "\n",
    "        for i in tqdm(range(self.maxIteration)):\n",
    "        # Shuffle x and y\n",
    "          np.random.shuffle(XY)\n",
    "\n",
    "          start = 0\n",
    "          stop = start + self.batchSize\n",
    "          X_batch, y_batch = XY[start:stop, :-1], XY[start:stop, -1]\n",
    "\n",
    "          \n",
    "          last_error = float('inf')\n",
    "\n",
    "          # Recalculating the difference\n",
    "          self.w = self.w - self.learningRate * self.gradient(X_batch, y_batch)\n",
    "          current_error = self.costFunction(X, y)\n",
    "         \n",
    "          diff = last_error - current_error\n",
    "          last_error = current_error\n",
    "\n",
    "          errors.append(current_error)\n",
    "          if np.abs(diff) < self.tolerance:\n",
    "              print('Model stopped learning')\n",
    "              break\n",
    "        print(self.w)\n",
    "        #self.plot_rmse(errors)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        pred = self.sigmoid(X.dot(self.w))\n",
    "        return np.around(pred)\n",
    "        \n",
    "    def evaluate(self, y, y_hat):\n",
    "        \n",
    "        y = (y == 1)\n",
    "        y_hat = (y_hat == 1)\n",
    "        \n",
    "        accuracy = (y == y_hat).sum() / y.size\n",
    "        precision = (y & y_hat).sum() / y_hat.sum()\n",
    "        recall = (y & y_hat).sum() / y.sum()\n",
    "\n",
    "        print(\"Accuracy is\", accuracy)\n",
    "        print('Recall is', recall)\n",
    "        print('precision is ', precision)\n",
    "        \n",
    "        return recall, precision, accuracy\n",
    "    \n",
    "    def fit(self):\n",
    "\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = self.splitData()\n",
    "        self.w = np.ones(X_train.shape[1], dtype = np.float64)*0\n",
    "        self.stochasticGD(X_train, y_train)\n",
    "        \n",
    "        #print(self.w)\n",
    "        \n",
    "        y_hat_train = self.predict(X_train)\n",
    "        recall, precision, accuracy = self.evaluate(y_train,y_hat_train)\n",
    "\n",
    "\n",
    "    def validation(self):\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = self.splitData()\n",
    "        y_hat_valid = self.predict(X_valid)\n",
    "        recall, precision, accuracy  = self.evaluate(y_valid, y_hat_valid)\n",
    "\n",
    "    def test(self):\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = self.splitData()\n",
    "        y_hat_test = self.predict(X_test)\n",
    "        recall, precision, accuracy  = self.evaluate(y_test, y_hat_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:38<00:00, 51.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01054954 -0.11060517 -0.03036936 -0.29551037 -0.16954511  0.31263985\n",
      " -0.07204962 -0.03989872  0.24805562 -0.24250005  0.10538828 -0.08570464\n",
      " -0.16990467  0.32665444 -0.0200231   0.07660875  0.01445947  0.04078251\n",
      " -0.11777394  0.08329929  0.13678689 -0.07204962 -0.65995702  0.73624118\n",
      " -0.28345799 -0.3492558   0.62747477  0.42252774 -0.35148262 -0.02627101\n",
      "  0.09731614  0.02690143  0.07295672 -0.0756326  -0.04977462  0.10317686\n",
      "  0.0298203  -0.07993337  0.04353041  0.01467862 -0.04544174  0.13739543\n",
      " -0.07106623  0.03547905  0.05255477 -0.01822515 -0.26365609  0.1167498\n",
      "  0.07236842  0.11125337  0.08200711 -0.11885353 -0.00255782  0.0259271\n",
      "  0.00098972 -0.01269256  0.08887318 -0.11848854  0.00202637  0.02661387\n",
      "  0.16690958  0.08679587 -0.01728303 -0.17192339  0.04517278  0.03805574\n",
      "  0.05599256 -0.01653694 -0.01785484  0.04760401 -0.06088314 -0.00947224\n",
      "  0.02344633  0.01739519 -0.09021824  0.04364294 -0.00097737  0.14164018\n",
      "  0.07911369  0.16026867 -0.07671192 -0.15467804 -0.1311698   0.00991679\n",
      "  0.18173882  0.08692958 -0.08648603 -0.0850171  -0.02612013  0.32813088\n",
      "  0.2113473   0.06931593 -0.06165523 -0.47609375  0.07049708  0.07322447\n",
      " -0.0057034  -0.07100497  0.00403194 -0.03367415 -0.04828316  0.11633513\n",
      " -0.02116214  0.05782944  0.11682055  0.13404581  0.03988187 -0.08940869\n",
      " -0.13029441]\n",
      "Accuracy is 0.6823430019712757\n",
      "Recall is 0.7648949320148332\n",
      "precision is  0.7033416685610366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7015765765765766\n",
      "Recall is 0.7916666666666666\n",
      "precision is  0.7137745974955277\n"
     ]
    }
   ],
   "source": [
    "lr.validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6875985286389911\n",
      "Recall is 0.7770050996754752\n",
      "precision is  0.7030201342281879\n"
     ]
    }
   ],
   "source": [
    "lr.test()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1143f320a06349356e2325743eda34a6c9064036a78c665fba996f767620c39f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projectVenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b8e6af7e1c800dc5745a28ff6ca8872762767d15c22a299591d50db6a7acdf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
