{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In vehicle coupon recommendation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [1 - Packages](#1) \n",
    "- [2 - Explornatory Data Analysis](#2)\n",
    "- [3 - Feature Enigineering](#3)\n",
    "- [4 - Classification Models](#4)\n",
    "- [5 - Clustering](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "from sklearn.feature_selection import chi2\n",
    "from scipy import stats\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Know your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Show the first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\Data-Science\\Course\\IE7374\\Projects\\ml_project\\Vehicle_Coupon.csv\")\n",
    "df.head()\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.2 Dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.3 Features Explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.4 Features Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.5 Null or not"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isnull().sum() / df.shape[0] * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Data Cleaning and transformation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1 Drop car column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(columns='car', inplace=True)\n",
    "# df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.2 Set data type as category"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.astype('category')\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.2 Impute lack data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Ref](https://jamesrledoux.com/code/imputation#:~:text=One%20approach%20to%20imputing%20categorical,given%20in%20Pandas'%20value_counts%20function.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "df.isnull().sum().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Exploratory Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Coupon acception vs. reject"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_pie(sizes, text,colors,labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    col = [[i/255. for i in c] for c in colors]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('equal')\n",
    "    width = 0.35\n",
    "    kwargs = dict(colors=col, startangle=180, autopct='%1.1f%%')\n",
    "    outside, _, _ = ax.pie(sizes, radius=1, pctdistance=1-width/2,\n",
    "                       labels=labels,**kwargs)\n",
    "    plt.setp( outside, width=width, edgecolor='white')\n",
    "\n",
    "    kwargs = dict(size=20, fontweight='bold', va='center')\n",
    "    ax.text(0, 0, text, ha='center', **kwargs)\n",
    "    plt.show()\n",
    "\n",
    "c1 = (226,33,7)\n",
    "c2 = (60,121,189)\n",
    "\n",
    "make_pie([257,90], \"Acception\",[c1,c2],['Y','N'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Which feature will be indepedent of target?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Ref](https://medium.com/analytics-vidhya/constructing-heat-map-for-chi-square-test-of-independence-6d78aa2b140f#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjFiZDY4NWY1ZThmYzYyZDc1ODcwNWMxZWIwZThhNzUyNGM0NzU5NzUiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2NTc1NzcwNTcsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjExNjk2NjQyODk4MDIxNTU1MjE0OSIsImVtYWlsIjoieWFubWluZ2xpdTIxQGdtYWlsLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJuYW1lIjoiWWFubWluZyBMaXUiLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUl0YnZtbW1DdnlEVzktaWF0dXQzYXhlQWFlZGpIWV9TY2laNWI4M3dfLTY9czk2LWMiLCJnaXZlbl9uYW1lIjoiWWFubWluZyIsImZhbWlseV9uYW1lIjoiTGl1IiwiaWF0IjoxNjU3NTc3MzU3LCJleHAiOjE2NTc1ODA5NTcsImp0aSI6IjhmMmJjM2MwOTk2NDZmMDdiODBhYTZmNWE5OGY5ZGU0YTk3YzAxMTQifQ.Tvz3S-XbT029APxcmsPETDBUj8S1ir0iYejfv9QbpWLtuCDYwxxbDuQv1FCL9Wz_D8hmxPutvuOgrF-dFT5oMYTq6rn0hV8Z0UNNn8rBR_KofiuSx10ChpZgJfmMAtqccsfW20Yk__v_xvZPNOLnjiHdXZAtoQiWUNo9VFAZ58NM98KjLfkkJ0r715iuIQrnyzWnUnabgwO96GT1OTaLynipdg6ugvClNENa3WZIncBtdqlP4jeTE7QOEPnTMRUntHGCTj5VRsnJRYt3OYpE6BqQgANptFUygI-K47IM5WSAicSFzmxyp9CgJxQ3U4d4S3LPKqiBy63v7gkxkLJPhQ)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.astype('object')\n",
    "column_names=df.columns\n",
    "\n",
    "chisqmatrix=pd.DataFrame(df,columns=column_names,index=column_names)\n",
    "\n",
    "\n",
    "outercnt=0\n",
    "innercnt=0\n",
    "for icol in column_names:\n",
    "    for jcol in column_names:\n",
    "       mycrosstab=pd.crosstab(df[icol],df[jcol])\n",
    "       stat,p,dof,expected=stats.chi2_contingency(mycrosstab)\n",
    "       chisqmatrix.iloc[outercnt,innercnt]=round(p,3)\n",
    "       cntexpected=expected[expected<5].size\n",
    "       perexpected=((expected.size-cntexpected)/expected.size)*100\n",
    "       if perexpected<20:\n",
    "            chisqmatrix.iloc[outercnt,innercnt]=2\n",
    "       if icol==jcol:\n",
    "           chisqmatrix.iloc[outercnt,innercnt]=0.00\n",
    "       innercnt=innercnt+1\n",
    "    outercnt=outercnt+1\n",
    "    innercnt=0\n",
    "    \n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "sns.heatmap(chisqmatrix.astype(np.float64), annot=True,linewidths=0.1, \n",
    "            cmap='coolwarm')\n",
    "\n",
    "# Question: 2 perspectives here. If we see the bottom row of this heatmap, \n",
    "# we can easily remove those with bigger p values with alpha = .05 for they \n",
    "# are indepdent. How do we deal those variables among features for a relatie\n",
    "# small value?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 How do the rest of feature will influence the target ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Ref](https://stackoverflow.com/questions/63687789/how-do-i-create-a-pie-chart-using-categorical-data-in-matplotlib)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 0\n",
    "target = df.columns[-1]\n",
    "for cat_val in df.columns:\n",
    "  if cat_val == target: \n",
    "    continue\n",
    "  temp_df = df.loc[:, [cat_val, target]]  \n",
    "  temp_df = temp_df.groupby([cat_val, target]).size().reset_index(name='count')\n",
    "  pivot_df = pd.pivot_table(temp_df, values='count', index=cat_val, columns=target)\n",
    "  pivot_df.plot(kind='bar')\n",
    "  count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 -  Feature selection\n",
    "We assume that the target and features are related only the confidence is above 95 percent. By observing the bottom row in the heatmap in section 2.2, those 3 columns, **toCoupon_GEQ5min, direction_same, direction_opp**, are removed as not meeting the confidence conditions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_droped = df.drop(columns = ['toCoupon_GEQ5min', 'direction_same', 'direction_opp'])\n",
    "print(len(df.columns))\n",
    "print(len(df_droped.columns))\n",
    "df_droped.to_csv('Clean_Data_0.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=3-2></a>\n",
    "### 3.2 - Feature encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in df_droped.columns:\n",
    "    print(i, df_droped[i].unique(), '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.1 - Load dataset "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Numpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    data = read_csv(filename, header=None)\n",
    "    dataset = data.values\n",
    "    \n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    \n",
    "    X = X.astype(str)\n",
    "    y = y.reshape((len(y), 1))\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test \n",
    "X, y = load_dataset('Clean_Data_0.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_droped.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target = ['Y']\n",
    "XP = df_droped.drop(columns = target)\n",
    "yP = df_droped[target]\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(XP, yP, test_size=0.3, random_state=0)\n",
    "XTrain.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='3-2-2'></a>\n",
    "#### 3.2.2 - Ordinal encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %pip install category_encoders\n",
    "import category_encoders as ce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Encoding categorical variables](https://kiwidamien.github.io/encoding-categorical-variables.html)\\\n",
    "[Target Encoding](https://medium.com/analytics-vidhya/target-encoding-vs-one-hot-encoding-with-simple-examples-276a7e7b3e64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ordinal_encoder(train, test, columns):\n",
    "    oe = ce.OrdinalEncoder(cols=columns, return_df=True)\n",
    "    train_transformed = oe.fit_transform(train)\n",
    "    test_transformed = oe.transform(test)\n",
    "    return train_transformed, test_transformed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_droped.columns)\n",
    "ordial_columns = ['age', 'education', 'income', 'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']\n",
    "XTrain_after_ordinal, XTest_after_ordinal = ordinal_encoder(XTrain, XTest, ordial_columns)\n",
    "display(XTrain.head())\n",
    "display(XTest.head())\n",
    "display(XTrain_after_ordinal.head())\n",
    "display(XTest_after_ordinal.head())\n",
    "\n",
    "# Question: Are time, temprature the ordinal variables?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ordinal_encoding(clean_df):\n",
    "    frequency_map = {\n",
    "        'never': 0,\n",
    "        'less1': 1,\n",
    "        '1~3': 2,\n",
    "        '4~8': 3,\n",
    "        'gt8': 4\n",
    "    }\n",
    "    \n",
    "    age_map = {\n",
    "        'below21': 0,\n",
    "        '21': 1,\n",
    "        '26': 2,\n",
    "        '31': 3,\n",
    "        '36': 4,\n",
    "        '41': 5,\n",
    "        '46': 6,\n",
    "        '50plus': 7\n",
    "    }\n",
    "    \n",
    "    income_map = {\n",
    "        'Less than $12500': 0,\n",
    "        '$12500 - $24999': 1,\n",
    "        '$25000 - $37499': 2,\n",
    "        '$37500 - $49999': 3,\n",
    "        '$50000 - $62499': 4,\n",
    "        '$62500 - $74999': 5,\n",
    "        '$75000 - $87499': 6,\n",
    "        '$87500 - $99999': 7,\n",
    "        '$100000 or More': 8\n",
    "    }\n",
    "    \n",
    "    frequency_cols = ['Restaurant20To50', 'RestaurantLessThan20',\n",
    "                      'CarryAway', 'CoffeeHouse', 'Bar']\n",
    "\n",
    "    \n",
    "    education_map = {\n",
    "        'Some High School': 0, \n",
    "        'High School Graduate': 1,\n",
    "        'Some college - no degree': 2,\n",
    "        'Associates degree': 3,\n",
    "        'Bachelors degree': 4,\n",
    "        'Graduate degree (Masters or Doctorate)': 5\n",
    "    }\n",
    "        \n",
    "    \n",
    "    for col in frequency_cols:\n",
    "        clean_df[col] = clean_df[col].map(frequency_map)\n",
    "    clean_df.age = clean_df.age.map(age_map)\n",
    "    clean_df.income = clean_df.income.map(income_map)\n",
    "    clean_df.education = clean_df.education.map(education_map)\n",
    "\n",
    "    return clean_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_droped.education.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_droped.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name = '3-2-2'></a>\n",
    "#### 3.2.2 - One hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def one_hot_encoding(train, test, columns):\n",
    "    oe = ce.OneHotEncoder(cols=columns, return_df=True)\n",
    "    train_transformed = oe.fit_transform(train)\n",
    "    test_transformed = oe.transform(test)\n",
    "    return train_transformed, test_transformed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_after_one_hot_encoding, test_after_one_hot_encoding = one_hot_encoding(XTrain, XTest, columns=[i for i in XTrain.columns if i not in ordial_columns])\n",
    "display(train_after_one_hot_encoding.head())\n",
    "display(test_after_one_hot_encoding.head())\n",
    "display(train_after_one_hot_encoding.age)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name = '3-2-3'></a>\n",
    "#### 3.2.3 - Frequency and target encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def target_encoding(train, ytrain, test, columns):\n",
    "    ytrain = ytrain.astype(float)\n",
    "    oe = ce.TargetEncoder(return_df=True)\n",
    "\n",
    "    train_transformed = oe.fit_transform(train[columns], ytrain[ytrain.columns])\n",
    "    test_transformed = oe.transform(test)\n",
    "    return train_transformed, test_transformed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_after_target_encoding, test_after_target_encoding = target_encoding(XTrain, yTrain, XTest, columns=list(XTrain.columns))\n",
    "display(train_after_target_encoding.head())\n",
    "display(test_after_target_encoding.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test cases\n",
    "import random\n",
    "\n",
    "from numpy import disp\n",
    "random.seed(4)\n",
    "data=pd.DataFrame({'class':['A','B','C','B','C','A','A','A'],\n",
    "                    'yes':['1','2','3','4','5','6','7','8'],\n",
    "                    'Marks':[random.randint(0,1) for i in range(8)]})\n",
    "encoder=ce.TargetEncoder(cols='class') \n",
    "display(data)\n",
    "encoder.fit_transform(data['class'],data['Marks'])\n",
    "\n",
    "X = data.drop(columns=['Marks'])\n",
    "y = data[['Marks']]\n",
    "display(X)\n",
    "display(y)\n",
    "x1, x2, y1, y2 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "display(pd.concat([x1, y1], axis=1))\n",
    "display(pd.concat([x2, y2], axis=1))\n",
    "display(x1)\n",
    "\n",
    "t1, t2 = target_encoding(x1, y1, x2, columns=list(x1.columns))\n",
    "display(t1)\n",
    "display(t2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name = '3-2-4'></a>\n",
    "#### 3.2.4 - Embedded encoding\n",
    "\n",
    "[Ref](https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import concatenate\n",
    "from keras.utils import plot_model\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=0).iloc[:,1:]\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\t# reshape target to be a 2d array\n",
    "\ty = y.reshape((len(y), 1))\n",
    "\treturn X, y\n",
    " \n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\tX_train_enc, X_test_enc = list(), list()\n",
    "\t# label encode each column\n",
    "\tfor i in range(X_train.shape[1]):\n",
    "\t\tle = LabelEncoder()\n",
    "\t\tle.fit(X_train[:, i])\n",
    "\t\t# encode\n",
    "\t\ttrain_enc = le.transform(X_train[:, i])\n",
    "\t\ttest_enc = le.transform(X_test[:, i])\n",
    "\t\t# store\n",
    "\t\tX_train_enc.append(train_enc)\n",
    "\t\tX_test_enc.append(test_enc)\n",
    "\treturn X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    " \n",
    "# load the dataset\n",
    "X_e, y_e = load_dataset('Clean_Data_0.csv')\n",
    "display(X_e, y_e)\n",
    "# split into train and test sets\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(X_e, y_e, test_size=0.3, random_state=0)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_Train, X_Test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_Train, y_Test)\n",
    "# make output 3d\n",
    "y_train_enc = y_train_enc.reshape((len(y_train_enc), 1, 1))\n",
    "y_test_enc = y_test_enc.reshape((len(y_test_enc), 1, 1))\n",
    "\n",
    "# prepare each input head\n",
    "in_layers = list()\n",
    "em_layers = list()\n",
    "for i in range(len(X_train_enc)):\n",
    "\t# calculate the number of unique inputs\n",
    "\tn_labels = len(unique(X_train_enc[i]))\n",
    "\t# define input layer\n",
    "\tin_layer = Input(shape=(1,))\n",
    "\t# define embedding layer\n",
    "\tem_layer = Embedding(n_labels, 10)(in_layer)\n",
    "\t# store layers\n",
    "\tin_layers.append(in_layer)\n",
    "\tem_layers.append(em_layer)\n",
    "# concat all embeddings\n",
    "merge = concatenate(em_layers)\n",
    "dense = Dense(10, activation='relu', kernel_initializer='he_normal')(merge)\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "model = Model(inputs=in_layers, outputs=output)\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# plot graph\n",
    "plot_model(model, show_shapes=True, to_file='embeddings.png')\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_enc, y_train_enc, epochs=20, batch_size=16, verbose=2)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(merge)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name = '4'></a>\n",
    "# 4 - Classifiaction Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name = '4-1'></a>\n",
    "### 4.1 - Logistic regression\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Target Encoding\n",
    "# %pip install dmba\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba import classificationSummary, gainsChart, liftChart\n",
    "\n",
    "display(train_after_target_encoding)\n",
    "lr = LogisticRegression()\n",
    "yTrain = yTrain.astype('category')\n",
    "yTest = yTest.astype('category')\n",
    "lr.fit(train_after_target_encoding, yTrain)\n",
    "classificationSummary(yTest, lr.predict(test_after_target_encoding))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One Hot Encoding \n",
    "XTrain_only_one_hot, XTest_only_one_hot = one_hot_encoding(XTrain, XTest, columns=XTrain.columns)\n",
    "display(XTrain_only_one_hot.head())\n",
    "lr.fit(XTrain_only_one_hot, yTrain)\n",
    "classificationSummary(yTest, lr.predict(XTest_only_one_hot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ordinal Encoding \n",
    "XTrain_only_ordinal, XTest_only_ordinal = ordinal_encoder(XTrain, XTest, columns=XTrain.columns)\n",
    "display(XTrain_only_ordinal.head())\n",
    "lr.fit(XTrain_only_ordinal, yTrain)\n",
    "classificationSummary(yTest, lr.predict(XTest_only_ordinal))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One Hot Encoding + Ordianal Encoding\n",
    "XTrain_after_ordinal, XTest_after_ordinal = ordinal_encoder(XTrain, XTest, ordial_columns)\n",
    "train_after_one_hot_encoding, test_after_one_hot_encoding = one_hot_encoding(XTrain_after_ordinal, XTest_after_ordinal, columns=[i for i in XTrain.columns if i not in ordial_columns])\n",
    "display(train_after_one_hot_encoding.head())\n",
    "display(test_after_one_hot_encoding)\n",
    "\n",
    "lr.fit(train_after_one_hot_encoding, yTrain)\n",
    "classificationSummary(yTest, lr.predict(test_after_one_hot_encoding))\n",
    "\n",
    "\n",
    "## Ordinal encoding with some order assignment\n",
    "target = ['Y']\n",
    "XP = df_droped.drop(columns = target)\n",
    "yP = df_droped[target]\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(XP, yP, test_size=0.3, random_state=0)\n",
    "display(XTrain.head())\n",
    "\n",
    "XTrain_after_ordinal_o = ordinal_encoding(XTrain)\n",
    "XTest_after_ordinal_o = ordinal_encoding(XTest)\n",
    "display(XTrain.head())\n",
    "display(XTrain_after_ordinal_o.isnull().sum())\n",
    "display(XTest_after_ordinal_o.isnull().sum())\n",
    "train_after_one_hot_encoding_n, test_after_one_hot_encoding_n = one_hot_encoding(XTrain_after_ordinal_o, XTest_after_ordinal_o, columns=[i for i in XTrain.columns if i not in ordial_columns])\n",
    "display(train_after_one_hot_encoding_n.head())\n",
    "display(test_after_one_hot_encoding_n)\n",
    "\n",
    "lr.fit(train_after_one_hot_encoding_n, yTrain)\n",
    "classificationSummary(yTest, lr.predict(test_after_one_hot_encoding_n))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Embedded Encoding\n",
    "# We have tested previously using neural network, how to apply to logistic \n",
    "# regression here?\n",
    "# It seems that the encoder has changed the dimension of the training data\n",
    "# so I am not sure if they are applicable to the logistic regression.\n",
    "display(len(em_layers))\n",
    "em_layers\n",
    "\n",
    "df_droped.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep Neural Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}